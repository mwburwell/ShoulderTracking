{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "import cv2\n",
    "from os.path import join\n",
    "\n",
    "from SlidingWindow import SlidingWindow\n",
    "from os.path import join\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstate in Notebook Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "asset_folder = join('..', 'assets')\n",
    "\n",
    "video = cv2.VideoCapture(join(asset_folder, 'shoulder-proj.mp4'))\n",
    "display_handle = display(None, display_id=True)\n",
    "\n",
    "try:\n",
    "    while video.isOpened():\n",
    "        isRunning, frame = video.read()\n",
    "        if isRunning:\n",
    "            gray_img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # find the faces in the image\n",
    "            face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "            faces = face_classifier.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=5, minSize=(40,40))\n",
    "            \n",
    "            # draws a rectangle for each face found in the image\n",
    "            for face in faces:\n",
    "                x, y, w, h = face\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), color=(255, 0, 0), thickness=5)\n",
    "\n",
    "            # display the frame in the jupyter notebook\n",
    "            _, frame = cv2.imencode('.jpeg', frame)\n",
    "            display_handle.update(Image(data= frame.tobytes()))\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    video.release()\n",
    "    display_handle.update(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def euclidean_distance(x, y, last_x, last_y):\n",
    "    return math.sqrt((x - last_x) ** 2 + (y - last_y) ** 2)\n",
    "\n",
    "def find_face_among_list(faces, last_bounding_box):\n",
    "    '''\n",
    "    The face classifier sometimes detects false faces.\n",
    "    This function tries to rectify that by recording the position of the previous face and \n",
    "    then finding the euclidean distance from all the faces detected in the next frame. The face\n",
    "    that is closest to the last frame is kept and the other is removed.\n",
    "    '''\n",
    "    min_dist = sys.maxsize\n",
    "    indx = 0\n",
    "        \n",
    "    for i, (x, y, w, h) in enumerate(faces):\n",
    "        last_x, last_y = last_bounding_box[0:2]\n",
    "        \n",
    "        temp_dist = euclidean_distance(x, y, last_x, last_y)\n",
    "        if temp_dist < min_dist:\n",
    "            min_dist = temp_dist\n",
    "            indx = i\n",
    "    \n",
    "    return indx\n",
    "\n",
    "def jitter_defender(new_line, old_line, threshold):\n",
    "    theta = math.tan(new_line[0] / old_line[0]) #(abs(new_line[0]) + abs(old_line[0])) / 2\n",
    "    if abs(theta) > threshold:\n",
    "        # print(f'return old line: {old_line} - {new_line} - {theta}')\n",
    "        return old_line\n",
    "    \n",
    "    # print(f'return new line: {old_line} - {new_line} - {theta}')\n",
    "    return new_line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def detect_bounding_box(img, last_bounding_box):\n",
    "    '''\n",
    "    Detects a face in the current image.\n",
    "\n",
    "    The classifier can sometimes detect false faces. find_face_among_list tries to remove the false\n",
    "    faces.\n",
    "    '''\n",
    "\n",
    "    # turn the image into a gray image.\n",
    "    # TODO: could be faster if the function was passed a gray image\n",
    "    # instead of making it.\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "    # detectMultiScale returns a sequence - _typing.Sequence[cv2.typing.Rect]\n",
    "    faces = face_classifier.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=5, minSize=(40,40))\n",
    "    \n",
    "    if len(faces) > 0:\n",
    "        indx = 0\n",
    "        if len(faces) > 1:\n",
    "            indx = find_face_among_list(faces, last_bounding_box)\n",
    "            x, y, w, h = faces[indx]\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 4)\n",
    "            \n",
    "        else:\n",
    "            x, y, w, h = faces[indx]\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 4)\n",
    "            \n",
    "        return faces, faces[indx]\n",
    "    else:\n",
    "        return faces, np.empty((1, 4))\n",
    "        \n",
    "    \n",
    "        \n",
    "    # for (x, y, w, h) in faces:\n",
    "    #     if len(faces) > 1:\n",
    "            \n",
    "    #     cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assets_folder = join('..', 'assets')\n",
    "\n",
    "\n",
    "video = cv2.VideoCapture(join(assets_folder, 'shoulder-proj.mp4'))\n",
    "last_box = np.array((1, 4))\n",
    "\n",
    "disp_handl = display(None, display_id=True)\n",
    "\n",
    "sentinel = True\n",
    "l_last_line = np.zeros((2))\n",
    "r_last_line = np.zeros((2))\n",
    "\n",
    "try:\n",
    "    while(video.isOpened()):\n",
    "    # capture frame by frame\n",
    "        result, frame = video.read()\n",
    "        # if not result:\n",
    "        #     break\n",
    "        \n",
    "        \n",
    "        faces, last_box = detect_bounding_box(frame, last_box)\n",
    "        if len(faces) > 0:\n",
    "            cv2.drawMarker(frame, (last_box[0], last_box[1]), markerSize=10, markerType=cv2.MARKER_STAR, color=(0,0,255))\n",
    "            gray_img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            blured_img = cv2.GaussianBlur(gray_img, (7, 7), 1)\n",
    "            minval = np.percentile(blured_img, 11)\n",
    "            maxval = np.percentile(blured_img, 100)\n",
    "\n",
    "            img_contrast = np.clip(blured_img.copy(), minval, maxval)\n",
    "            img_contrast = ((img_contrast - minval) / (maxval - minval)) * 255\n",
    "            x, y, w, h = last_box\n",
    "            \n",
    "            # left and right should windows\n",
    "            displacment = 0\n",
    "            # print(x - w + displacment)\n",
    "            # print(x)\n",
    "            ls_window_img = img_contrast[y: (y + h + w), (x - w + displacment) : x]\n",
    "            rs_window_img = img_contrast[y: (y + h + w), (x + w): (x + (2 * w) - displacment)]\n",
    "            \n",
    "            height = ls_window_img.shape[0]\n",
    "            length = ls_window_img.shape[1]\n",
    "            \n",
    "            sig = round(height / 1.85)\n",
    "            med = round(height / 1.85)\n",
    "            left_shoulder_window = SlidingWindow(ls_window_img, 64, median= med, sigma= sig, constant=10)\n",
    "            right_shoulder_window = SlidingWindow(rs_window_img, 64, median= med, sigma= sig, constant=10)\n",
    "            \n",
    "            left_line_vector = np.polyfit(left_shoulder_window.x_positions[:,0], left_shoulder_window.y_positions[:,0], 1)\n",
    "            right_line_vector = np.polyfit(right_shoulder_window.x_positions[:,0], right_shoulder_window.y_positions[:,0], 1)\n",
    "            \n",
    "            if l_last_line[0] == 0:\n",
    "                l_last_line = left_line_vector\n",
    "            if r_last_line[0] == 0:\n",
    "                r_last_line = right_line_vector\n",
    "            \n",
    "            left_line_vector = jitter_defender(left_line_vector, l_last_line, 5)\n",
    "            right_line_vector = jitter_defender(right_line_vector, r_last_line, 5)\n",
    "            \n",
    "            \n",
    "            l_start_y = round(left_line_vector[1] + h)\n",
    "            l_end_y = round(length * left_line_vector[0] + left_line_vector[1] + h)\n",
    "            cv2.line(frame, (0 + x - w, l_start_y), (length + x - w, l_end_y), (0,0,255), 3)\n",
    "            \n",
    "            r_start_y = round(right_line_vector[1] + h)\n",
    "            r_end_y = round(length * right_line_vector[0] + right_line_vector[1] + h)\n",
    "            cv2.line(frame, (0 + x + w, r_start_y), (length + x + w, r_end_y), (0,0,255), 3)\n",
    "            \n",
    "            if sentinel and len(faces) > 1:\n",
    "                plt.title(\"Top & Bottom Segmentation\")\n",
    "                plt.imshow(ls_window_img, cmap=\"gray\")\n",
    "                plt.scatter(left_shoulder_window.x_positions[:, 0], left_shoulder_window.y_positions[:, 0])\n",
    "                # plt.plot(up_low_seg_line.x_values, up_low_seg_line.y_values, color=\"red\")\n",
    "                # plt.plot(firstWindow.x_positions, np.polyval(line_vector, firstWindow.x_positions), color=\"red\")\n",
    "                plt.show()\n",
    "                left_shoulder_window.sampling(30, 'Test')\n",
    "                sentinel = False\n",
    "\n",
    "            l_last_line = left_line_vector\n",
    "            r_last_line = right_line_vector\n",
    "        cv2.imshow('frame', frame)\n",
    "        # cv2.imshow('frame', integral_img)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "# video.release()\n",
    "# cv2.destroyAllWindows()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trackenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
